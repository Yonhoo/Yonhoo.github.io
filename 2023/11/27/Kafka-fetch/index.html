<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Kafka-Fetch | Yonhoo</title>
  <link rel="stylesheet" href="/css/fonts/Chinese-normal-normal.min.css">
  <link rel="stylesheet" href="/css/fonts/ChineseMono-normal-normal.min.css">
  <link rel="stylesheet" href="/css/fonts/Chinese-italic-normal.min.css">
  <link rel="stylesheet" href="/css/fonts/Chinese-normal-bold.min.css">


  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- SEO Meta Tags -->
  
  <meta name="description" content="  每个Broker上都有一个ReplicaManager，它管理每个Partition的数据同步逻辑，因为每个Partition都会存在副本，从而在Broker中的TopicPartition可能是Leader或者Follower。
  当它是Leader时，就需要处理来自Producer的请求，写入log数据，同时等ISR集合同步完成，如果是Follower，就需要同步来自Leader的log数据，保持数据同步。
  在ReplicaManager中，就会开启同步Follower线程来FetchMessage。在ReplicaManager中会调用makeFollowers来处理同步Leader数据的逻辑。">
  
  
  <!-- Keywords -->
  
  <meta name="keywords" content="programming, database, mongodb, elasticsearch, monstache, tech blog, development, tutorial">
  
  
  <!-- Author -->
  <meta name="author" content="epic">
  
  <!-- Open Graph Meta Tags -->
  <meta property="og:type" content="article">
  <meta property="og:title" content="Kafka-Fetch | Yonhoo">
  <meta property="og:url" content="https://Yonhoo.github.io/2023/11/27/Kafka-fetch/">
  <meta property="og:site_name" content="Yonhoo">
  
  <meta property="og:description" content="A tech blog recording development experiences, tutorials, and personal insights on programming, databases, and technology trends.">
  
  
  <!-- Twitter Card Meta Tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Kafka-Fetch | Yonhoo">
  
  <meta name="twitter:description" content="A tech blog recording development experiences, tutorials, and personal insights on programming, databases, and technology trends.">
  
  
  <!-- Canonical URL -->
  <link rel="canonical" href="https://Yonhoo.github.io/2023/11/27/Kafka-fetch/">
  
  <!-- Language -->
  <meta http-equiv="content-language" content="en">
  
    <link rel="alternate" href="/atom.xml" title="Yonhoo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  <!-- 额外的favicon格式支持 -->
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="stylesheet" href="/css/style.css">
  
    <link rel="stylesheet" href="/fancybox/jquery.fancybox-1.3.4.css">
  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <div id="nav-outer">
  <nav id="main-nav" class="outer">
    <a id="main-nav-toggle" class="nav-icon"></a>
    
      <a class="main-nav-link" href="/archives">Home</a>
    
      <a class="main-nav-link" href="/archives">Archives</a>
    
      <a class="main-nav-link" href="/about">About</a>
    
    <div class="main-nav-space-between"></div>
    
      <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
    
  </nav>
</div>

<div id="header-title">
  <h1 id="logo-wrap">
    <a href="/" id="logo">Yonhoo</a>
  </h1>
  
    <h2 id="subtitle-wrap">
      <a href="/" id="subtitle">Tech Blog &amp; Personal Journey</a>
    </h2>
  
</div>

      <div id="content" class="outer">
        <section id="main"><article id="post-Kafka-fetch" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/11/27/Kafka-fetch/" class="article-date">
  <time class="dt-published" datetime="2023-11-26T16:00:00.000Z" itemprop="datePublished">2023-11-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/">分布式系统</a>►<a class="article-category-link" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/">消息中间件</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Kafka-Fetch
    </h1>
  

      </header>
    
    
<!-- 鼠标悬停触发区域 -->
<div class="toc-hover-trigger"></div>

<!-- 左侧边栏TOC -->
<div id="sidebar-toc" class="sidebar-toc">
    <div class="toc-toggle" id="toc-toggle">
        <i class="fa fa-list"></i>
        <span>目录</span>
    </div>
    <div class="toc-content" id="toc-content">
        <div class="toc-header">
            <h3 class="toc-title">Table Of Contents</h3>
        </div>
        <div class="toc-body">
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#fetch-%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5"><span class="toc-number">1.</span> <span class="toc-text">Fetch 线程同步</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-maybetruncate()"><span class="toc-number">1.1.</span> <span class="toc-text">1. maybeTruncate()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-maybefetch"><span class="toc-number">1.2.</span> <span class="toc-text">2. maybeFetch</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-completedelayedfetchrequests"><span class="toc-number">1.3.</span> <span class="toc-text">3. completeDelayedFetchRequests</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#handlefetchrequest"><span class="toc-number">1.4.</span> <span class="toc-text">HandleFetchRequest</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%82%E5%B8%B8%E6%83%85%E5%86%B5%EF%BC%9A"><span class="toc-number">1.4.1.</span> <span class="toc-text">异常情况：</span></a></li></ol></li></ol></li></ol>
        </div>
    </div>
</div>

<!-- TOC遮罩层 -->
<div id="toc-overlay" class="toc-overlay"></div>

<!-- TOC JavaScript -->
<script>
document.addEventListener('DOMContentLoaded', function() {
    const tocToggle = document.getElementById('toc-toggle');
    const tocContent = document.getElementById('toc-content');
    const tocOverlay = document.getElementById('toc-overlay');
    const sidebarToc = document.getElementById('sidebar-toc');
    const tocLinks = tocContent.querySelectorAll('.toc-link');
    
    // 切换TOC显示状态
    function toggleToc() {
        sidebarToc.classList.toggle('active');
        tocOverlay.classList.toggle('active');
        document.body.classList.toggle('toc-open');
    }
    
    // 关闭TOC
    function closeToc() {
        sidebarToc.classList.remove('active');
        tocOverlay.classList.remove('active');
        document.body.classList.remove('toc-open');
    }
    
    // 事件监听
    tocToggle.addEventListener('click', toggleToc);
    tocOverlay.addEventListener('click', closeToc);
    
    // TOC链接点击后自动关闭（移动端）
    tocLinks.forEach(link => {
        link.addEventListener('click', function() {
            if (window.innerWidth <= 768) {
                setTimeout(closeToc, 300); // 延迟关闭，让滚动完成
            }
        });
    });
    
    // 键盘ESC关闭
    document.addEventListener('keydown', function(e) {
        if (e.key === 'Escape') {
            closeToc();
        }
    });
    
    // 窗口大小变化时的处理
    window.addEventListener('resize', function() {
        if (window.innerWidth > 768) {
            closeToc();
        }
    });
    
    // 滚动监听，高亮当前章节
    let headings = [];
    tocLinks.forEach(link => {
        const href = link.getAttribute('href');
        if (href && href.startsWith('#')) {
            const target = document.querySelector(href);
            if (target) {
                headings.push({
                    link: link,
                    target: target,
                    offset: target.offsetTop
                });
            }
        }
    });
    
    function updateActiveHeading() {
        const scrollTop = window.pageYOffset || document.documentElement.scrollTop;
        const windowHeight = window.innerHeight;
        let activeHeading = null;
        
        // 找到当前可视区域内的标题
        for (let i = headings.length - 1; i >= 0; i--) {
            const heading = headings[i];
            if (scrollTop >= heading.offset - 100) {
                activeHeading = heading;
                break;
            }
        }
        
        // 更新高亮状态
        tocLinks.forEach(link => link.classList.remove('active'));
        if (activeHeading) {
            activeHeading.link.classList.add('active');
            
            // 滚动TOC到当前项
            const tocBody = document.querySelector('.toc-body');
            if (tocBody && sidebarToc.classList.contains('active')) {
                const linkTop = activeHeading.link.offsetTop;
                const tocBodyHeight = tocBody.offsetHeight;
                const linkHeight = activeHeading.link.offsetHeight;
                
                if (linkTop < tocBody.scrollTop || linkTop > tocBody.scrollTop + tocBodyHeight - linkHeight) {
                    tocBody.scrollTop = linkTop - tocBodyHeight / 2;
                }
            }
        }
    }
    
    // 节流函数
    function throttle(func, wait) {
        let timeout;
        return function executedFunction(...args) {
            const later = () => {
                clearTimeout(timeout);
                func(...args);
            };
            clearTimeout(timeout);
            timeout = setTimeout(later, wait);
        };
    }
    
    // 绑定滚动事件
    window.addEventListener('scroll', throttle(updateActiveHeading, 100));
    
    // 初始化高亮
    updateActiveHeading();
});
</script>

    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>  每个Broker上都有一个ReplicaManager，它管理每个Partition的数据同步逻辑，因为每个Partition都会存在副本，从而在Broker中的TopicPartition可能是Leader或者Follower。</p>
<p>  当它是Leader时，就需要处理来自Producer的请求，写入log数据，同时等ISR集合同步完成，如果是Follower，就需要同步来自Leader的log数据，保持数据同步。</p>
<p>  在ReplicaManager中，就会开启同步Follower线程来FetchMessage。在ReplicaManager中会调用makeFollowers来处理同步Leader数据的逻辑。</p>
<span id="more"></span>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> def <span class="hljs-title function_">makeFollowers</span><span class="hljs-params">(controllerId: Int,</span><br><span class="hljs-params">                          controllerEpoch: Int,</span><br><span class="hljs-params">                          partitionStates: Map[Partition, LeaderAndIsrPartitionState],</span><br><span class="hljs-params">                          correlationId: Int,</span><br><span class="hljs-params">                          responseMap: mutable.Map[TopicPartition, Errors],</span><br><span class="hljs-params">                          highWatermarkCheckpoints: OffsetCheckpoints,</span><br><span class="hljs-params">                          topicIds: String =&gt; Option[Uuid])</span>: Set[Partition] = &#123;<br>  <span class="hljs-type">val</span> <span class="hljs-variable">traceLoggingEnabled</span> <span class="hljs-operator">=</span> stateChangeLogger.isTraceEnabled<br>  partitionStates.forKeyValue &#123; (partition, partitionState) =&gt;<br>    responseMap.put(partition.topicPartition, Errors.NONE)<br>  &#125;<br><br>  val partitionsToMakeFollower: mutable.Set[Partition] = mutable.Set()<br>  <span class="hljs-keyword">try</span> &#123;<br>    partitionStates.forKeyValue &#123; (partition, partitionState) =&gt;<br>      <span class="hljs-type">val</span> <span class="hljs-variable">newLeaderBrokerId</span> <span class="hljs-operator">=</span> partitionState.leader<br>      <span class="hljs-keyword">try</span> &#123;<br>        <span class="hljs-keyword">if</span> (metadataCache.hasAliveBroker(newLeaderBrokerId)) &#123;<br>          <span class="hljs-comment">// Only change partition state when the leader is available  </span><br>          <span class="hljs-keyword">if</span> (partition.makeFollower(partitionState, highWatermarkCheckpoints, topicIds(partitionState.topicName))) &#123;<br>            partitionsToMakeFollower += partition<br>          &#125;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>          <span class="hljs-comment">// The leader broker should always be present in the metadata cache.  </span><br>          <span class="hljs-comment">// If not, we should record the error message and abort the transition process for this partition  </span><br>          stateChangeLogger.error(s<span class="hljs-string">&quot;Received LeaderAndIsrRequest with correlation id $correlationId from &quot;</span> +<br>            s<span class="hljs-string">&quot;controller $controllerId epoch $controllerEpoch for partition $&#123;partition.topicPartition&#125; &quot;</span> +<br>            s<span class="hljs-string">&quot;(last update controller epoch $&#123;partitionState.controllerEpoch&#125;) &quot;</span> +<br>            s<span class="hljs-string">&quot;but cannot become follower since the new leader $newLeaderBrokerId is unavailable.&quot;</span>)<br>          <span class="hljs-comment">// Create the local replica even if the leader is unavailable. This is required to ensure that we include  </span><br>          <span class="hljs-comment">// the partition&#x27;s high watermark in the checkpoint file (see KAFKA-1647)  </span><br>          partition.createLogIfNotExists(isNew = partitionState.isNew, isFutureReplica = <span class="hljs-literal">false</span>,<br>            highWatermarkCheckpoints, topicIds(partitionState.topicName))<br>        &#125;<br>      &#125; <span class="hljs-keyword">catch</span> &#123;<br>        <span class="hljs-keyword">case</span> e: KafkaStorageException =&gt;<br>          stateChangeLogger.error(s<span class="hljs-string">&quot;Skipped the become-follower state change with correlation id $correlationId from &quot;</span> +<br>            s<span class="hljs-string">&quot;controller $controllerId epoch $controllerEpoch for partition $&#123;partition.topicPartition&#125; &quot;</span> +<br>            s<span class="hljs-string">&quot;(last update controller epoch $&#123;partitionState.controllerEpoch&#125;) with leader &quot;</span> +<br>            s<span class="hljs-string">&quot;$newLeaderBrokerId since the replica for the partition is offline due to storage error $e&quot;</span>)<br>          <span class="hljs-comment">// If there is an offline log directory, a Partition object may have been created and have been added  </span><br>          <span class="hljs-comment">// to `ReplicaManager.allPartitions` before `createLogIfNotExists()` failed to create local replica due  </span><br>          <span class="hljs-comment">// to KafkaStorageException. In this case `ReplicaManager.allPartitions` will map this topic-partition  </span><br>          <span class="hljs-comment">// to an empty Partition object. We need to map this topic-partition to OfflinePartition instead.  </span><br>          markPartitionOffline(partition.topicPartition)<br>          responseMap.put(partition.topicPartition, Errors.KAFKA_STORAGE_ERROR)<br>      &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// Stopping the fetchers must be done first in order to initialize the fetch  </span><br>    <span class="hljs-comment">// position correctly.  </span><br>    replicaFetcherManager.removeFetcherForPartitions(partitionsToMakeFollower.map(_.topicPartition))<br>    stateChangeLogger.info(s<span class="hljs-string">&quot;Stopped fetchers as part of become-follower request from controller $controllerId &quot;</span> +<br>      s<span class="hljs-string">&quot;epoch $controllerEpoch with correlation id $correlationId for $&#123;partitionsToMakeFollower.size&#125; partitions&quot;</span>)<br><br>    partitionsToMakeFollower.foreach &#123; partition =&gt;<br>      completeDelayedFetchOrProduceRequests(partition.topicPartition)<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> (isShuttingDown.get()) &#123;<br>      ...<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-comment">// we do not need to check if the leader exists again since this has been done at the beginning of this process  </span><br>      <span class="hljs-type">val</span> <span class="hljs-variable">partitionsToMakeFollowerWithLeaderAndOffset</span> <span class="hljs-operator">=</span> partitionsToMakeFollower.map &#123; partition =&gt;<br>        <span class="hljs-type">val</span> <span class="hljs-variable">leaderNode</span> <span class="hljs-operator">=</span> partition.leaderReplicaIdOpt.flatMap(leaderId =&gt; metadataCache.<br>          getAliveBrokerNode(leaderId, config.interBrokerListenerName)).getOrElse(Node.noNode())<br>        <span class="hljs-type">val</span> <span class="hljs-variable">leader</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">BrokerEndPoint</span>(leaderNode.id(), leaderNode.host(), leaderNode.port())<br>        <span class="hljs-type">val</span> <span class="hljs-variable">log</span> <span class="hljs-operator">=</span> partition.localLogOrException<br>        <span class="hljs-type">val</span> <span class="hljs-variable">fetchOffset</span> <span class="hljs-operator">=</span> initialFetchOffset(log)<br>        partition.topicPartition -&gt; InitialFetchState(topicIds(partition.topic), leader, partition.getLeaderEpoch, fetchOffset)<br>      &#125;.toMap<br><br>      replicaFetcherManager.addFetcherForPartitions(partitionsToMakeFollowerWithLeaderAndOffset)<br>    &#125;<br>  &#125; <span class="hljs-keyword">catch</span> &#123;<br>    <span class="hljs-keyword">case</span> e: Throwable =&gt;<br>      stateChangeLogger.error(s<span class="hljs-string">&quot;Error while processing LeaderAndIsr request with correlationId $correlationId &quot;</span> +<br>        s<span class="hljs-string">&quot;received from controller $controllerId epoch $controllerEpoch&quot;</span>, e)<br>      <span class="hljs-comment">// Re-throw the exception for it to be caught in KafkaApis  </span><br>      <span class="hljs-keyword">throw</span> e<br>  &#125;<br><br>  partitionsToMakeFollower<br>&#125;<br></code></pre></td></tr></table></figure>
<p>源码注释了什么情况下会将partition变成Follower,makeFollowers这个方法会在handleLeaderAndIsrRequest中被调用</p>
<figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs arcade"><span class="hljs-comment">/*  </span><br><span class="hljs-comment">* Make the current broker to become follower for a given set of partitions by:  </span><br><span class="hljs-comment">*  </span><br><span class="hljs-comment">* 1. Remove these partitions from the leader partitions set.  </span><br><span class="hljs-comment">* 2. Mark the replicas as followers so that no more data can be added from the producer clients.  </span><br><span class="hljs-comment">* 3. Stop fetchers for these partitions so that no more data can be added by the replica fetcher threads.  </span><br><span class="hljs-comment">* 4. Truncate the log and checkpoint offsets for these partitions.  </span><br><span class="hljs-comment">* 5. Clear the produce and fetch requests in the purgatory  </span><br><span class="hljs-comment">* 6. If the broker is not shutting down, add the fetcher to the new leaders.  </span><br><span class="hljs-comment">*  </span><br><span class="hljs-comment">* The ordering of doing these steps make sure that the replicas in transition will not  </span><br><span class="hljs-comment">* take any more messages before checkpointing offsets so that all messages before the checkpoint  </span><br><span class="hljs-comment">* are guaranteed to be flushed to disks  </span><br><span class="hljs-comment">*  </span><br><span class="hljs-comment">* If an unexpected error is thrown in this function, it will be propagated to KafkaApis where  </span><br><span class="hljs-comment">* the error message will be set on each partition since we do not know which partition caused it. Otherwise,  </span><br><span class="hljs-comment">* return the set of partitions that are made follower due to this method  </span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure>
<p>makeFollowers主要的steps：</p>
<ul>
<li>
<p>partitionsToMakeFollower 里面包含的是Leader发生改变的partition</p>
</li>
<li>
<p>接下来removeFetcherForPartitions会从fetcher线程中移除对partition的同步，为了保证从新Leader中从正确的位置开始同步</p>
</li>
<li>
<p>completeDelayedFetchOrProduceRequests，完成那些之前异步的Fetch操作</p>
</li>
<li>
<p>之后会将同步的信息包装成Map[TopicPartition, InitialFetchState]，里面包含的信息如下代码，之后将此信息放进Fetcher线程中进行同步</p>
</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">val</span> partitionsToMakeFollowerWithLeaderAndOffset = partitionsToMakeFollower.map &#123; partition =&gt;<br>  <span class="hljs-keyword">val</span> leaderNode = partition.leaderReplicaIdOpt.flatMap(leaderId =&gt; metadataCache.<br>    getAliveBrokerNode(leaderId, config.interBrokerListenerName)).getOrElse(<span class="hljs-type">Node</span>.noNode())<br>  <span class="hljs-keyword">val</span> leader = <span class="hljs-keyword">new</span> <span class="hljs-type">BrokerEndPoint</span>(leaderNode.id(), leaderNode.host(), leaderNode.port())<br>  <span class="hljs-keyword">val</span> log = partition.localLogOrException<br>  <span class="hljs-keyword">val</span> fetchOffset = initialFetchOffset(log)<br>  partition.topicPartition -&gt; <span class="hljs-type">InitialFetchState</span>(topicIds(partition.topic), leader, partition.getLeaderEpoch, fetchOffset)<br>&#125;.toMap<br></code></pre></td></tr></table></figure>
<h2 id="fetch-线程同步">Fetch 线程同步</h2>
<p>  replica线程在启动后，就会进行同步操作，ReplicaFetcherThread会调用doWork()：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">override</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">doWork</span></span>(): <span class="hljs-type">Unit</span> = &#123;  <br>    maybeTruncate()  <br>    maybeFetch()<br>    completeDelayedFetchRequests()  <br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="1-maybetruncate()">1. maybeTruncate()</h3>
<p>  maybeTruncate会将Leader Offset改变的follower进行高水位或者LeaderEpoch进行重新平衡，先不深入LeaderEpoch</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> def <span class="hljs-title function_">maybeTruncate</span><span class="hljs-params">()</span>: Unit = &#123;<br>  val (partitionsWithEpochs, partitionsWithoutEpochs) =<br>    fetchTruncatingPartitions()<br>  <span class="hljs-keyword">if</span> (partitionsWithEpochs.nonEmpty) &#123;<br>    truncateToEpochEndOffsets(partitionsWithEpochs)<br>  &#125;<br>  <span class="hljs-keyword">if</span> (partitionsWithoutEpochs.nonEmpty) &#123;<br>    truncateToHighWatermark(partitionsWithoutEpochs)<br>  &#125;<br>&#125;<br><br><br><span class="hljs-keyword">private</span>[server] def <span class="hljs-title function_">truncateToHighWatermark</span><span class="hljs-params">(partitions: Set[TopicPartition])</span>: Unit = inLock(partitionMapLock) &#123;<br>  <span class="hljs-type">val</span> <span class="hljs-variable">fetchOffsets</span> <span class="hljs-operator">=</span> mutable.HashMap.empty[TopicPartition, OffsetTruncationState]<br><br>  <span class="hljs-keyword">for</span> (tp &lt;- partitions) &#123;<br>    <span class="hljs-type">val</span> <span class="hljs-variable">partitionState</span> <span class="hljs-operator">=</span> partitionStates.stateValue(tp)<br>    <span class="hljs-keyword">if</span> (partitionState != <span class="hljs-literal">null</span>) &#123;<br>      <span class="hljs-type">val</span> <span class="hljs-variable">highWatermark</span> <span class="hljs-operator">=</span> partitionState.fetchOffset<br>      <span class="hljs-type">val</span> <span class="hljs-variable">truncationState</span> <span class="hljs-operator">=</span> OffsetTruncationState(highWatermark, truncationCompleted = <span class="hljs-literal">true</span>)<br><br>      info(s<span class="hljs-string">&quot;Truncating partition $tp with $truncationState due to local high watermark $highWatermark&quot;</span>)<br>      <span class="hljs-keyword">if</span> (doTruncate(tp, truncationState))<br>        fetchOffsets.put(tp, truncationState)<br>    &#125;<br>  &#125;<br><br>  updateFetchOffsetAndMaybeMarkTruncationComplete(fetchOffsets)<br>&#125;<br><br></code></pre></td></tr></table></figure>
<p>  truncateToHighWatermark会将partitionsWithoutEpochs中所有处isTruncating状态的local partition's offset更新成新Leader Partition高水位的offset,因为有些处于Truncating的partition可能Log end offset已经大于新Leader的高水位，此时进行截断，从新Leader的高水位开始进行同步</p>
<h3 id="2-maybefetch">2. maybeFetch</h3>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maybeFetch</span></span>(): <span class="hljs-type">Unit</span> = &#123;<br>  <span class="hljs-keyword">val</span> fetchRequestOpt = inLock(partitionMapLock) &#123;<br>    <span class="hljs-keyword">val</span> <span class="hljs-type">ResultWithPartitions</span>(fetchRequestOpt, partitionsWithError) = leader.buildFetch(partitionStates.partitionStateMap.asScala)<br><br>    handlePartitionsWithErrors(partitionsWithError, <span class="hljs-string">&quot;maybeFetch&quot;</span>)<br><br>    <span class="hljs-keyword">if</span> (fetchRequestOpt.isEmpty) &#123;<br>      trace(<span class="hljs-string">s&quot;There are no active partitions. Back off for <span class="hljs-subst">$fetchBackOffMs</span> ms before sending a fetch request&quot;</span>)<br>      partitionMapCond.await(fetchBackOffMs, <span class="hljs-type">TimeUnit</span>.<span class="hljs-type">MILLISECONDS</span>)<br>    &#125;<br><br>    fetchRequestOpt<br>  &#125;<br><br>  fetchRequestOpt.foreach &#123; <span class="hljs-keyword">case</span> <span class="hljs-type">ReplicaFetch</span>(sessionPartitions, fetchRequest) =&gt;<br>    processFetchRequest(sessionPartitions, fetchRequest)<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>maybeFetch主要是组装fetchRequest:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">new</span> <span class="hljs-type">FetchRequest</span>.<span class="hljs-type">PartitionData</span>(<br>            fetchState.topicId.getOrElse(<span class="hljs-type">Uuid</span>.<span class="hljs-type">ZERO_UUID</span>),<br>            fetchState.fetchOffset, <span class="hljs-comment">//logAppendInfo.lastOffset + 1</span><br>            logStartOffset,<br>            fetchSize,<br>            <span class="hljs-type">Optional</span>.of(fetchState.currentLeaderEpoch),<br>            lastFetchedEpoch)<br><br></code></pre></td></tr></table></figure>
<p>  然后发送请求到Leader所在的Broker，之后进行follower副本offset的更新。processFetchRequest中将fetchRequest放入sender线程中进行请求</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">processFetchRequest</span></span>(sessionPartitions: util.<span class="hljs-type">Map</span>[<span class="hljs-type">TopicPartition</span>, <span class="hljs-type">FetchRequest</span>.<span class="hljs-type">PartitionData</span>],<br>                                fetchRequest: <span class="hljs-type">FetchRequest</span>.<span class="hljs-type">Builder</span>): <span class="hljs-type">Unit</span> = &#123;<br>  <span class="hljs-keyword">val</span> partitionsWithError = mutable.<span class="hljs-type">Set</span>[<span class="hljs-type">TopicPartition</span>]()<br>  <span class="hljs-keyword">val</span> divergingEndOffsets = mutable.<span class="hljs-type">Map</span>.empty[<span class="hljs-type">TopicPartition</span>, <span class="hljs-type">EpochEndOffset</span>]<br>  <span class="hljs-keyword">var</span> responseData: <span class="hljs-type">Map</span>[<span class="hljs-type">TopicPartition</span>, <span class="hljs-type">FetchData</span>] = <span class="hljs-type">Map</span>.empty<br><br>  <span class="hljs-keyword">try</span> &#123;<br>    trace(<span class="hljs-string">s&quot;Sending fetch request <span class="hljs-subst">$fetchRequest</span>&quot;</span>)<br>    responseData = leader.fetch(fetchRequest)<br>  &#125; <span class="hljs-keyword">catch</span> &#123;<br>    ...<br>  &#125;<br>  fetcherStats.requestRate.mark()<br><br>  <span class="hljs-keyword">if</span> (responseData.nonEmpty) &#123;<br>    <span class="hljs-comment">// process fetched data</span><br>    inLock(partitionMapLock) &#123;<br>      responseData.forKeyValue &#123; (topicPartition, partitionData) =&gt;<br>        <span class="hljs-type">Option</span>(partitionStates.stateValue(topicPartition)).foreach &#123; currentFetchState =&gt;<br>          <span class="hljs-comment">// It&#x27;s possible that a partition is removed and re-added or truncated when there is a pending fetch request.</span><br>          <span class="hljs-comment">// In this case, we only want to process the fetch response if the partition state is ready for fetch and</span><br>          <span class="hljs-comment">// the current offset is the same as the offset requested.</span><br>          <span class="hljs-keyword">val</span> fetchPartitionData = sessionPartitions.get(topicPartition)<br>          <span class="hljs-keyword">if</span> (fetchPartitionData != <span class="hljs-literal">null</span> &amp;&amp; fetchPartitionData.fetchOffset == currentFetchState.fetchOffset &amp;&amp; currentFetchState.isReadyForFetch) &#123;<br>            <span class="hljs-type">Errors</span>.forCode(partitionData.errorCode) <span class="hljs-keyword">match</span> &#123;<br>              <span class="hljs-keyword">case</span> <span class="hljs-type">Errors</span>.<span class="hljs-type">NONE</span> =&gt;<br>                <span class="hljs-keyword">try</span> &#123;<br>                  <span class="hljs-keyword">if</span> (leader.isTruncationOnFetchSupported &amp;&amp; <span class="hljs-type">FetchResponse</span>.isDivergingEpoch(partitionData)) &#123;<br>                    ...<br>                  &#125; <span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-comment">// Once we hand off the partition data to the subclass, we can&#x27;t mess with it any more in this thread</span><br>                    <span class="hljs-keyword">val</span> logAppendInfoOpt = processPartitionData(<br>                      topicPartition,<br>                      currentFetchState.fetchOffset,<br>                      partitionData<br>                    )<br><br>                    logAppendInfoOpt.foreach &#123; logAppendInfo =&gt;<br>                      <span class="hljs-keyword">val</span> validBytes = logAppendInfo.validBytes<br>                      <span class="hljs-keyword">val</span> nextOffset = <span class="hljs-keyword">if</span> (validBytes &gt; <span class="hljs-number">0</span>) logAppendInfo.lastOffset + <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> currentFetchState.fetchOffset<br>                      <span class="hljs-keyword">val</span> lag = <span class="hljs-type">Math</span>.max(<span class="hljs-number">0</span>L, partitionData.highWatermark - nextOffset)<br>                      fetcherLagStats.getAndMaybePut(topicPartition).lag = lag<br><br>                      <span class="hljs-comment">// ReplicaDirAlterThread may have removed topicPartition from the partitionStates after processing the partition data</span><br>                      <span class="hljs-keyword">if</span> ((validBytes &gt; <span class="hljs-number">0</span> || currentFetchState.lag.isEmpty) &amp;&amp; partitionStates.contains(topicPartition)) &#123;<br>                        <span class="hljs-comment">// Update partitionStates only if there is no exception during processPartitionData</span><br>                        <span class="hljs-keyword">val</span> newFetchState = <span class="hljs-type">PartitionFetchState</span>(currentFetchState.topicId, nextOffset, <span class="hljs-type">Some</span>(lag),<br>                          currentFetchState.currentLeaderEpoch, state = <span class="hljs-type">Fetching</span>,<br>                          logAppendInfo.lastLeaderEpoch.asScala)<br>                        partitionStates.updateAndMoveToEnd(topicPartition, newFetchState)<br>                        <span class="hljs-keyword">if</span> (validBytes &gt; <span class="hljs-number">0</span>) fetcherStats.byteRate.mark(validBytes)<br>                      &#125;<br>                    &#125;<br>                  &#125;<br>                &#125;<br><br>            &#125;<br>    ...<br>    &#125;<br></code></pre></td></tr></table></figure>
<p>当response返回了数据，调用processPartitionData更新follower的log end offset,其中processPartitionData会进行partition.append操作;当写完本地log后，更新partitionState.updateAndMoveToEnd，</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">override</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">processPartitionData</span></span>(topicPartition: <span class="hljs-type">TopicPartition</span>,<br>                                  fetchOffset: <span class="hljs-type">Long</span>,<br>                                  partitionData: <span class="hljs-type">FetchData</span>): <span class="hljs-type">Option</span>[<span class="hljs-type">LogAppendInfo</span>] = &#123;<br>  <span class="hljs-keyword">val</span> logTrace = isTraceEnabled<br>  <span class="hljs-keyword">val</span> partition = replicaMgr.getPartitionOrException(topicPartition)<br>  <span class="hljs-keyword">val</span> log = partition.localLogOrException<br>  <span class="hljs-keyword">val</span> records = toMemoryRecords(<span class="hljs-type">FetchResponse</span>.recordsOrFail(partitionData))<br><br>  maybeWarnIfOversizedRecords(records, topicPartition)<br><br>  <span class="hljs-keyword">if</span> (fetchOffset != log.logEndOffset)<br>    <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">IllegalStateException</span>(<span class="hljs-string">&quot;Offset mismatch for partition %s: fetched offset = %d, log end offset = %d.&quot;</span>.format(<br>      topicPartition, fetchOffset, log.logEndOffset))<br><br>  <span class="hljs-keyword">if</span> (logTrace)<br>    trace(<span class="hljs-string">&quot;Follower has replica log end offset %d for partition %s. Received %d bytes of messages and leader hw %d&quot;</span><br>      .format(log.logEndOffset, topicPartition, records.sizeInBytes, partitionData.highWatermark))<br><br>  <span class="hljs-comment">// Append the leader&#x27;s messages to the log  </span><br>  <span class="hljs-keyword">val</span> logAppendInfo = partition.appendRecordsToFollowerOrFutureReplica(records, isFuture = <span class="hljs-literal">false</span>)<br><br>  <span class="hljs-keyword">if</span> (logTrace)<br>    trace(<span class="hljs-string">&quot;Follower has replica log end offset %d after appending %d bytes of messages for partition %s&quot;</span><br>      .format(log.logEndOffset, records.sizeInBytes, topicPartition))<br>  <span class="hljs-keyword">val</span> leaderLogStartOffset = partitionData.logStartOffset<br><br>  <span class="hljs-comment">// For the follower replica, we do not need to keep its segment base offset and physical position.  </span><br>  <span class="hljs-comment">// These values will be computed upon becoming leader or handling a preferred read replica fetch.  </span><br>  <span class="hljs-keyword">var</span> maybeUpdateHighWatermarkMessage = <span class="hljs-string">s&quot;but did not update replica high watermark&quot;</span><br>  log.maybeUpdateHighWatermark(partitionData.highWatermark).foreach &#123; newHighWatermark =&gt;<br>    maybeUpdateHighWatermarkMessage = <span class="hljs-string">s&quot;and updated replica high watermark to <span class="hljs-subst">$newHighWatermark</span>&quot;</span><br>    partitionsWithNewHighWatermark += topicPartition<br>  &#125;<br><br>  log.maybeIncrementLogStartOffset(leaderLogStartOffset, <span class="hljs-type">LogStartOffsetIncrementReason</span>.<span class="hljs-type">LeaderOffsetIncremented</span>)<br>  <span class="hljs-keyword">if</span> (logTrace)<br>    trace(<span class="hljs-string">s&quot;Follower received high watermark <span class="hljs-subst">$&#123;partitionData.highWatermark&#125;</span> from the leader &quot;</span> +<br>      <span class="hljs-string">s&quot;<span class="hljs-subst">$maybeUpdateHighWatermarkMessage</span> for partition <span class="hljs-subst">$topicPartition</span>&quot;</span>)<br><br>  <span class="hljs-comment">// Traffic from both in-sync and out of sync replicas are accounted for in replication quota to ensure total replication  </span><br>  <span class="hljs-comment">// traffic doesn&#x27;t exceed quota.  </span><br>  <span class="hljs-keyword">if</span> (quota.isThrottled(topicPartition))<br>    quota.record(records.sizeInBytes)<br><br>  <span class="hljs-keyword">if</span> (partition.isReassigning &amp;&amp; partition.isAddingLocalReplica)<br>    brokerTopicStats.updateReassignmentBytesIn(records.sizeInBytes)<br><br>  brokerTopicStats.updateReplicationBytesIn(records.sizeInBytes)<br><br>  logAppendInfo<br>&#125;<br></code></pre></td></tr></table></figure>
<ul>
<li>maybeUpdateHighWatermark
<ul>
<li>如果leader的partition高水位发生改变，就更新follower的高水位</li>
</ul>
</li>
<li>maybeIncrementLogStartOffset
<ul>
<li>如果leader的logStartOffset更新了，也需要更新本地副本的logStartOffset。</li>
</ul>
</li>
</ul>
<h3 id="3-completedelayedfetchrequests">3. completeDelayedFetchRequests</h3>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">completeDelayedFetchRequests</span></span>(): <span class="hljs-type">Unit</span> = &#123;  <br>    <span class="hljs-keyword">if</span> (partitionsWithNewHighWatermark.nonEmpty) &#123;  <br>            replicaMgr.completeDelayedFetchRequests(<br>                partitionsWithNewHighWatermark.toSeq)  <br>    partitionsWithNewHighWatermark.clear()  <br>&#125;  <br>&#125;<br><br><br><span class="hljs-keyword">private</span>[server] <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">completeDelayedFetchRequests</span></span>(topicPartitions: <span class="hljs-type">Seq</span>[<span class="hljs-type">TopicPartition</span>]): <span class="hljs-type">Unit</span> = &#123;  <br>    topicPartitions.foreach(tp =&gt; delayedFetchPurgatory.checkAndComplete(<span class="hljs-type">TopicPartitionOperationKey</span>(tp)))  <br>&#125;<br></code></pre></td></tr></table></figure>
<p>  刚开始还有个疑问，为什么follower中还有completeDelayedFetchRequests操作，刚看了<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-392%3A+Allow+consumers+to+fetch+from+closest+replica#KIP392:Allowconsumerstofetchfromclosestreplica-ConsumerAPI">KIP-392</a>,其中描述了避免跨机房从Leader中获取消息外，Kafka支持从就近的Replica中获取消息，从而就会存在consumer fetch request from follower，于是就会存在delayedFetch操作，从而当follower的高水位更新后，避免因replica.fetch.wait.max.ms超时才响应，而是在更新高水位后就立即尝试响应</p>
<ul>
<li>
<h3 id="handlefetchrequest">HandleFetchRequest</h3>
</li>
</ul>
<p>  当Broker server收到fetchRequest后，KafkaApis会将其mapping到handleFetchRequest的方法中来处理，下面来详细介绍其处理方式：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><code class="hljs scala">  <br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">handleFetchRequest</span></span>(request: <span class="hljs-type">RequestChannel</span>.<span class="hljs-type">Request</span>): <span class="hljs-type">Unit</span> = &#123;<br>  <span class="hljs-keyword">val</span> versionId = request.header.apiVersion<br>  <span class="hljs-keyword">val</span> clientId = request.header.clientId<br>  <span class="hljs-keyword">val</span> fetchRequest = request.body[<span class="hljs-type">FetchRequest</span>]<br>  <span class="hljs-keyword">val</span> topicNames =<br>    <span class="hljs-keyword">if</span> (fetchRequest.version() &gt;= <span class="hljs-number">13</span>)<br>      metadataCache.topicIdsToNames()<br>    <span class="hljs-keyword">else</span><br>      <span class="hljs-type">Collections</span>.emptyMap[<span class="hljs-type">Uuid</span>, <span class="hljs-type">String</span>]()<br><br>  <span class="hljs-keyword">val</span> fetchData = fetchRequest.fetchData(topicNames)<br>  <span class="hljs-keyword">val</span> forgottenTopics = fetchRequest.forgottenTopics(topicNames)<br><br>  <span class="hljs-keyword">val</span> fetchContext = fetchManager.newContext(<br>    fetchRequest.version,<br>    fetchRequest.metadata,<br>    fetchRequest.isFromFollower,<br>    fetchData,<br>    forgottenTopics,<br>    topicNames)<br><br>  <span class="hljs-keyword">val</span> erroneous = mutable.<span class="hljs-type">ArrayBuffer</span>[(<span class="hljs-type">TopicIdPartition</span>, <span class="hljs-type">FetchResponseData</span>.<span class="hljs-type">PartitionData</span>)]()<br>  <span class="hljs-keyword">val</span> interesting = mutable.<span class="hljs-type">ArrayBuffer</span>[(<span class="hljs-type">TopicIdPartition</span>, <span class="hljs-type">FetchRequest</span>.<span class="hljs-type">PartitionData</span>)]()<br>  <span class="hljs-keyword">if</span> (fetchRequest.isFromFollower) &#123;<br>    <span class="hljs-comment">// The follower must have ClusterAction on ClusterResource in order to fetch partition data.</span><br>    <span class="hljs-keyword">if</span> (authHelper.authorize(request.context, <span class="hljs-type">CLUSTER_ACTION</span>, <span class="hljs-type">CLUSTER</span>, <span class="hljs-type">CLUSTER_NAME</span>)) &#123;<br>      fetchContext.foreachPartition &#123; (topicIdPartition, data) =&gt;<br>        interesting += topicIdPartition -&gt; data<br>      &#125;<br>    &#125;<br>    ...<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    ...<br>  &#125;<br><br><br>  <span class="hljs-comment">// the callback for process a fetch response, invoked before throttling</span><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">processResponseCallback</span></span>(responsePartitionData: <span class="hljs-type">Seq</span>[(<span class="hljs-type">TopicIdPartition</span>, <span class="hljs-type">FetchPartitionData</span>)]): <span class="hljs-type">Unit</span> = &#123;<br>    <span class="hljs-keyword">val</span> partitions = <span class="hljs-keyword">new</span> util.<span class="hljs-type">LinkedHashMap</span>[<span class="hljs-type">TopicIdPartition</span>, <span class="hljs-type">FetchResponseData</span>.<span class="hljs-type">PartitionData</span>]<br>    <span class="hljs-keyword">val</span> reassigningPartitions = mutable.<span class="hljs-type">Set</span>[<span class="hljs-type">TopicIdPartition</span>]()<br>    responsePartitionData.foreach &#123; <span class="hljs-keyword">case</span> (tp, data) =&gt;<br>      <span class="hljs-keyword">val</span> abortedTransactions = data.abortedTransactions.orElse(<span class="hljs-literal">null</span>)<br>      <span class="hljs-keyword">val</span> lastStableOffset: <span class="hljs-type">Long</span> = data.lastStableOffset.orElse(<span class="hljs-type">FetchResponse</span>.<span class="hljs-type">INVALID_LAST_STABLE_OFFSET</span>)<br>      <span class="hljs-keyword">if</span> (data.isReassignmentFetch) reassigningPartitions.add(tp)<br>      <span class="hljs-keyword">val</span> partitionData = <span class="hljs-keyword">new</span> <span class="hljs-type">FetchResponseData</span>.<span class="hljs-type">PartitionData</span>()<br>        .setPartitionIndex(tp.partition)<br>        .setErrorCode(maybeDownConvertStorageError(data.error).code)<br>        .setHighWatermark(data.highWatermark)<br>        .setLastStableOffset(lastStableOffset)<br>        .setLogStartOffset(data.logStartOffset)<br>        .setAbortedTransactions(abortedTransactions)<br>        .setRecords(data.records)<br>        .setPreferredReadReplica(data.preferredReadReplica.orElse(<span class="hljs-type">FetchResponse</span>.<span class="hljs-type">INVALID_PREFERRED_REPLICA_ID</span>))<br>      data.divergingEpoch.ifPresent(partitionData.setDivergingEpoch(_))<br>      partitions.put(tp, partitionData)<br>    &#125;<br>    erroneous.foreach &#123; <span class="hljs-keyword">case</span> (tp, data) =&gt; partitions.put(tp, data) &#125;<br><br><br>    <span class="hljs-comment">// Prepare fetch response from converted data</span><br>    <span class="hljs-keyword">val</span> response =<br>      <span class="hljs-type">FetchResponse</span>.of(unconvertedFetchResponse.error, throttleTimeMs, unconvertedFetchResponse.sessionId, convertedData)<br>    <span class="hljs-comment">// record the bytes out metrics only when the response is being sent</span><br>    response.data.responses.forEach &#123; topicResponse =&gt;<br>      topicResponse.partitions.forEach &#123; data =&gt;<br>        <span class="hljs-comment">// If the topic name was not known, we will have no bytes out.</span><br>        <span class="hljs-keyword">if</span> (topicResponse.topic != <span class="hljs-literal">null</span>) &#123;<br>          <span class="hljs-keyword">val</span> tp = <span class="hljs-keyword">new</span> <span class="hljs-type">TopicIdPartition</span>(topicResponse.topicId, <span class="hljs-keyword">new</span> <span class="hljs-type">TopicPartition</span>(topicResponse.topic, data.partitionIndex))<br>          brokerTopicStats.updateBytesOut(tp.topic, fetchRequest.isFromFollower, reassigningPartitions.contains(tp), <span class="hljs-type">FetchResponse</span>.recordsSize(data))<br>        &#125;<br>      &#125;<br>    &#125;<br>    response<br>  &#125;<br><br>  <span class="hljs-keyword">if</span> (fetchRequest.isFromFollower) &#123;<br>    <span class="hljs-comment">// We&#x27;ve already evaluated against the quota and are good to go. Just need to record it now.</span><br>    unconvertedFetchResponse = fetchContext.updateAndGenerateResponseData(partitions)<br>    <span class="hljs-keyword">val</span> responseSize = <span class="hljs-type">KafkaApis</span>.sizeOfThrottledPartitions(versionId, unconvertedFetchResponse, quotas.leader)<br>    quotas.leader.record(responseSize)<br>    <span class="hljs-keyword">val</span> responsePartitionsSize = unconvertedFetchResponse.data().responses().stream().mapToInt(_.partitions().size()).sum()<br>    trace(<span class="hljs-string">s&quot;Sending Fetch response with partitions.size=<span class="hljs-subst">$responsePartitionsSize</span>, &quot;</span> +<br>      <span class="hljs-string">s&quot;metadata=<span class="hljs-subst">$&#123;unconvertedFetchResponse.sessionId&#125;</span>&quot;</span>)<br>    requestHelper.sendResponseExemptThrottle(request, createResponse(<span class="hljs-number">0</span>), <span class="hljs-type">Some</span>(updateConversionStats))<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    ...<br>  &#125;<br>&#125;<br><br><span class="hljs-keyword">if</span> (interesting.isEmpty) &#123;<br>  processResponseCallback(<span class="hljs-type">Seq</span>.empty)<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>  <span class="hljs-comment">// for fetch from consumer, cap fetchMaxBytes to the maximum bytes that could be fetched without being throttled given</span><br>  <span class="hljs-comment">// no bytes were recorded in the recent quota window</span><br>  <span class="hljs-comment">// trying to fetch more bytes would result in a guaranteed throttling potentially blocking consumer progress</span><br>  <span class="hljs-keyword">val</span> maxQuotaWindowBytes = <span class="hljs-keyword">if</span> (fetchRequest.isFromFollower)<br>    <span class="hljs-type">Int</span>.<span class="hljs-type">MaxValue</span><br>  <span class="hljs-keyword">else</span><br>    quotas.fetch.getMaxValueInQuotaWindow(request.session, clientId).toInt<br><br>  <span class="hljs-keyword">val</span> fetchMaxBytes = <span class="hljs-type">Math</span>.min(<span class="hljs-type">Math</span>.min(fetchRequest.maxBytes, config.fetchMaxBytes), maxQuotaWindowBytes)<br>  <span class="hljs-keyword">val</span> fetchMinBytes = <span class="hljs-type">Math</span>.min(fetchRequest.minBytes, fetchMaxBytes)<br><br>  <span class="hljs-keyword">val</span> clientMetadata: <span class="hljs-type">Optional</span>[<span class="hljs-type">ClientMetadata</span>] = <span class="hljs-keyword">if</span> (versionId &gt;= <span class="hljs-number">11</span>) &#123;<br>    <span class="hljs-comment">// Fetch API version 11 added preferred replica logic</span><br>    <span class="hljs-type">Optional</span>.of(<span class="hljs-keyword">new</span> <span class="hljs-type">DefaultClientMetadata</span>(<br>      fetchRequest.rackId,<br>      clientId,<br>      request.context.clientAddress,<br>      request.context.principal,<br>      request.context.listenerName.value))<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-type">Optional</span>.empty()<br>  &#125;<br><br>  <span class="hljs-keyword">val</span> params = <span class="hljs-keyword">new</span> <span class="hljs-type">FetchParams</span>(<br>    versionId,<br>    fetchRequest.replicaId,<br>    fetchRequest.replicaEpoch,<br>    fetchRequest.maxWait,<br>    fetchMinBytes,<br>    fetchMaxBytes,<br>    <span class="hljs-type">FetchIsolation</span>.of(fetchRequest),<br>    clientMetadata<br>  )<br><br>  <span class="hljs-comment">// call the replica manager to fetch messages from the local replica</span><br>  replicaManager.fetchMessages(<br>    params = params,<br>    fetchInfos = interesting,<br>    quota = replicationQuota(fetchRequest),<br>    responseCallback = processResponseCallback,<br>  )<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>其主要就是调用replicaManager.fetchMessages：</p>
<ol>
<li>ReplicaManager 处理 Fetch 请求看起来比较清晰，先是readFromLog，将topicIdPartition请求的logReadResult读取出来</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">readFromLog</span></span>(<br>                 params: <span class="hljs-type">FetchParams</span>,<br>                 readPartitionInfo: <span class="hljs-type">Seq</span>[(<span class="hljs-type">TopicIdPartition</span>, <span class="hljs-type">PartitionData</span>)],<br>                 quota: <span class="hljs-type">ReplicaQuota</span>,<br>                 readFromPurgatory: <span class="hljs-type">Boolean</span>): <span class="hljs-type">Seq</span>[(<span class="hljs-type">TopicIdPartition</span>, <span class="hljs-type">LogReadResult</span>)] = &#123;<br>  <span class="hljs-keyword">val</span> traceEnabled = isTraceEnabled<br>      ...<br>  <span class="hljs-keyword">var</span> limitBytes = params.maxBytes<br>  <span class="hljs-keyword">val</span> result = <span class="hljs-keyword">new</span> mutable.<span class="hljs-type">ArrayBuffer</span>[(<span class="hljs-type">TopicIdPartition</span>, <span class="hljs-type">LogReadResult</span>)]<br>  <span class="hljs-keyword">var</span> minOneMessage = !params.hardMaxBytesLimit<br>  readPartitionInfo.foreach &#123; <span class="hljs-keyword">case</span> (tp, fetchInfo) =&gt;<br>    <span class="hljs-keyword">val</span> readResult = read(tp, fetchInfo, limitBytes, minOneMessage)<br>    <span class="hljs-keyword">val</span> recordBatchSize = readResult.info.records.sizeInBytes<br>    <span class="hljs-comment">// Once we read from a non-empty partition, we stop ignoring request and partition level size limits  </span><br>    <span class="hljs-keyword">if</span> (recordBatchSize &gt; <span class="hljs-number">0</span>)<br>      minOneMessage = <span class="hljs-literal">false</span><br>    limitBytes = math.max(<span class="hljs-number">0</span>, limitBytes - recordBatchSize)<br>    result += (tp -&gt; readResult)<br>  &#125;<br>  result<br>&#125;<br></code></pre></td></tr></table></figure>
<p>  核心是在read里面,先是getPartition，然后根据fetchInfo从相应的partition中fetchRecords</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">read</span></span>(tp: <span class="hljs-type">TopicIdPartition</span>, fetchInfo: <span class="hljs-type">PartitionData</span>, limitBytes: <span class="hljs-type">Int</span>, minOneMessage: <span class="hljs-type">Boolean</span>): <span class="hljs-type">LogReadResult</span> = &#123;<br>  <span class="hljs-keyword">val</span> offset = fetchInfo.fetchOffset<br>  <span class="hljs-keyword">val</span> partitionFetchSize = fetchInfo.maxBytes<br>  <span class="hljs-keyword">val</span> followerLogStartOffset = fetchInfo.logStartOffset<br><br>  <span class="hljs-keyword">val</span> adjustedMaxBytes = math.min(fetchInfo.maxBytes, limitBytes)<br>  <span class="hljs-keyword">var</span> log: <span class="hljs-type">UnifiedLog</span> = <span class="hljs-literal">null</span><br>  <span class="hljs-keyword">var</span> partition: <span class="hljs-type">Partition</span> = <span class="hljs-literal">null</span><br>  <span class="hljs-keyword">val</span> fetchTimeMs = time.milliseconds<br>  <span class="hljs-keyword">try</span> &#123;<br><br>    partition = getPartitionOrException(tp.topicPartition)<br><br>    <span class="hljs-comment">// Check if topic ID from the fetch request/session matches the ID in the log  </span><br>    <span class="hljs-keyword">val</span> topicId = <span class="hljs-keyword">if</span> (tp.topicId == <span class="hljs-type">Uuid</span>.<span class="hljs-type">ZERO_UUID</span>) <span class="hljs-type">None</span> <span class="hljs-keyword">else</span> <span class="hljs-type">Some</span>(tp.topicId)<br>    <span class="hljs-keyword">if</span> (!hasConsistentTopicId(topicId, partition.topicId))<br>      <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">InconsistentTopicIdException</span>(<span class="hljs-string">&quot;Topic ID in the fetch session did not match the topic ID in the log.&quot;</span>)<br><br>    log = partition.localLogWithEpochOrThrow(<br>      fetchInfo.currentLeaderEpoch, params.fetchOnlyLeader())<br><br>    <span class="hljs-comment">// Try the read first, this tells us whether we need all of adjustedFetchSize for this partition  </span><br>    <span class="hljs-keyword">val</span> readInfo: <span class="hljs-type">LogReadInfo</span> = partition.fetchRecords(<br>      fetchParams = params,<br>      fetchPartitionData = fetchInfo,<br>      fetchTimeMs = fetchTimeMs,<br>      maxBytes = adjustedMaxBytes,<br>      minOneMessage = minOneMessage,<br>      updateFetchState = !readFromPurgatory)<br><br>    <span class="hljs-keyword">val</span> fetchDataInfo = checkFetchDataInfo(partition, readInfo.fetchedData)<br><br>    <span class="hljs-type">LogReadResult</span>(info = fetchDataInfo,<br>      divergingEpoch = readInfo.divergingEpoch.asScala,<br>      highWatermark = readInfo.highWatermark,<br>      leaderLogStartOffset = readInfo.logStartOffset,<br>      leaderLogEndOffset = readInfo.logEndOffset,<br>      followerLogStartOffset = followerLogStartOffset,<br>      fetchTimeMs = fetchTimeMs,<br>      lastStableOffset = <span class="hljs-type">Some</span>(readInfo.lastStableOffset),<br>      preferredReadReplica = preferredReadReplica,<br>      exception = <span class="hljs-type">None</span><br>    )<br>  &#125;<br><br>&#125;<br></code></pre></td></tr></table></figure>
<p><strong>fetchRecords</strong>会先readFromLocalLog,然后执行updateFollowerFetchState</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fetchRecords</span></span>(<br>                  fetchParams: <span class="hljs-type">FetchParams</span>,<br>                  fetchPartitionData: <span class="hljs-type">FetchRequest</span>.<span class="hljs-type">PartitionData</span>,<br>                  fetchTimeMs: <span class="hljs-type">Long</span>,<br>                  maxBytes: <span class="hljs-type">Int</span>,<br>                  minOneMessage: <span class="hljs-type">Boolean</span>,<br>                  updateFetchState: <span class="hljs-type">Boolean</span><br>                ): <span class="hljs-type">LogReadInfo</span> = &#123;<br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">readFromLocalLog</span></span>(log: <span class="hljs-type">UnifiedLog</span>): <span class="hljs-type">LogReadInfo</span> = &#123;<br>    readRecords(<br>      log,<br>      fetchPartitionData.lastFetchedEpoch,<br>      fetchPartitionData.fetchOffset,<br>      fetchPartitionData.currentLeaderEpoch,<br>      maxBytes,<br>      fetchParams.isolation,<br>      minOneMessage<br>    )<br>  &#125;<br><br>  <span class="hljs-keyword">if</span> (fetchParams.isFromFollower) &#123;<br>    <span class="hljs-comment">// Check that the request is from a valid replica before doing the read  </span><br>    <span class="hljs-keyword">val</span> (replica, logReadInfo) = inReadLock(leaderIsrUpdateLock) &#123;<br>      <span class="hljs-keyword">val</span> localLog = localLogWithEpochOrThrow(<br>        fetchPartitionData.currentLeaderEpoch,<br>        fetchParams.fetchOnlyLeader<br>      )<br>      <span class="hljs-keyword">val</span> replica = followerReplicaOrThrow(<br>        fetchParams.replicaId,<br>        fetchPartitionData<br>      )<br>      <span class="hljs-keyword">val</span> logReadInfo = readFromLocalLog(localLog)<br>      (replica, logReadInfo)<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> (updateFetchState &amp;&amp; !logReadInfo.divergingEpoch.isPresent) &#123;<br>      updateFollowerFetchState(<br>        replica,<br>        followerFetchOffsetMetadata = logReadInfo.fetchedData.fetchOffsetMetadata,<br>        followerStartOffset = fetchPartitionData.logStartOffset,<br>        followerFetchTimeMs = fetchTimeMs,<br>        leaderEndOffset = logReadInfo.logEndOffset,<br>        fetchParams.replicaEpoch<br>      )<br>    &#125;<br><br>    logReadInfo<br>  &#125;<br></code></pre></td></tr></table></figure>
<p>  readFromLocalLog先不介绍日志层，我们看获取到logReadInfo以后，执行了哪些更新操作</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs scala">updateFollowerFetchState(<br>  replica, <span class="hljs-comment">// 根据replicaId和fetchData获取相应的remoteReplica</span><br>  followerFetchOffsetMetadata =<br>    logReadInfo.fetchedData.fetchOffsetMetadata,<br>  followerStartOffset = fetchPartitionData.logStartOffset,<br>  followerFetchTimeMs = fetchTimeMs,<br>  leaderEndOffset = logReadInfo.logEndOffset,<br>  fetchParams.replicaEpoch<br>)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">updateFollowerFetchState</span></span>(<br>                              replica: <span class="hljs-type">Replica</span>,<br>                              followerFetchOffsetMetadata: <span class="hljs-type">LogOffsetMetadata</span>,<br>                              followerStartOffset: <span class="hljs-type">Long</span>,<br>                              followerFetchTimeMs: <span class="hljs-type">Long</span>,<br>                              leaderEndOffset: <span class="hljs-type">Long</span>,<br>                              brokerEpoch: <span class="hljs-type">Long</span><br>                            ): <span class="hljs-type">Unit</span> = &#123;<br>  <span class="hljs-comment">// No need to calculate low watermark if there is no delayed DeleteRecordsRequest  </span><br>  <span class="hljs-keyword">val</span> oldLeaderLW = <span class="hljs-keyword">if</span> (delayedOperations.numDelayedDelete &gt; <span class="hljs-number">0</span>) lowWatermarkIfLeader <span class="hljs-keyword">else</span> <span class="hljs-number">-1</span>L<br>  <span class="hljs-keyword">val</span> prevFollowerEndOffset = replica.stateSnapshot.logEndOffset<br>  replica.updateFetchState(<br>    followerFetchOffsetMetadata,<br>    followerStartOffset,<br>    followerFetchTimeMs,<br>    leaderEndOffset,<br>    brokerEpoch<br>  )<br><br>  <span class="hljs-keyword">val</span> newLeaderLW = <span class="hljs-keyword">if</span> (delayedOperations.numDelayedDelete &gt; <span class="hljs-number">0</span>) lowWatermarkIfLeader <span class="hljs-keyword">else</span> <span class="hljs-number">-1</span>L<br>  <span class="hljs-comment">// check if the LW of the partition has incremented  </span><br>  <span class="hljs-comment">// since the replica&#x27;s logStartOffset may have incremented  </span><br>  <span class="hljs-keyword">val</span> leaderLWIncremented = newLeaderLW &gt; oldLeaderLW<br><br>  <span class="hljs-comment">// Check if this in-sync replica needs to be added to the ISR.  </span><br>  maybeExpandIsr(replica)<br><br>  <span class="hljs-comment">// check if the HW of the partition can now be incremented  </span><br>  <span class="hljs-comment">// since the replica may already be in the ISR and its LEO has just incremented  </span><br>  <span class="hljs-keyword">val</span> leaderHWIncremented = <span class="hljs-keyword">if</span> (prevFollowerEndOffset != replica.stateSnapshot.logEndOffset) &#123;<br>    <span class="hljs-comment">// the leader log may be updated by ReplicaAlterLogDirsThread so the following method must be in lock of  </span><br>    <span class="hljs-comment">// leaderIsrUpdateLock to prevent adding new hw to invalid log.  </span><br>    inReadLock(leaderIsrUpdateLock) &#123;<br>      leaderLogIfLocal.exists(leaderLog =&gt; maybeIncrementLeaderHW(leaderLog, followerFetchTimeMs))<br>    &#125;<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-literal">false</span><br>  &#125;<br><br>  <span class="hljs-comment">// some delayed operations may be unblocked after HW or LW changed  </span><br>  <span class="hljs-keyword">if</span> (leaderLWIncremented || leaderHWIncremented)<br>    tryCompleteDelayedRequests()<br><br>  debug(<span class="hljs-string">s&quot;Recorded replica <span class="hljs-subst">$&#123;replica.brokerId&#125;</span> log end offset (LEO) position &quot;</span> +<br>    <span class="hljs-string">s&quot;<span class="hljs-subst">$&#123;followerFetchOffsetMetadata.messageOffset&#125;</span> and log start offset <span class="hljs-subst">$followerStartOffset</span>.&quot;</span>)<br>&#125;<br><br></code></pre></td></tr></table></figure>
<ul>
<li>replica执行updateFetchState，更新follower Replica的offset信息</li>
<li>maybeExpandIsr判断如果replica的offset已经追赶上leader的endOffset，就提示可能要更新Isr集合</li>
</ul>
<p>注释解释了当 LEO &gt;= HW &amp;&amp; followerEndOffset &gt;= leaderEpochStartOffsetOpt ,就可以加入ISR</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs scala">  <span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Check and maybe expand the ISR of the partition.</span><br><span class="hljs-comment">   * A replica will be added to ISR if its LEO &gt;= current hw of the partition and it is caught up to</span><br><span class="hljs-comment">   * an offset within the current leader epoch. A replica must be caught up to the current leader</span><br><span class="hljs-comment">   * epoch before it can join ISR, because otherwise, if there is committed data between current</span><br><span class="hljs-comment">   * leader&#x27;s HW and LEO, the replica may become the leader before it fetches the committed data</span><br><span class="hljs-comment">   * and the data will be lost.</span><br><span class="hljs-comment">   *</span><br><span class="hljs-comment">   * Technically, a replica shouldn&#x27;t be in ISR if it hasn&#x27;t caught up for longer than replicaLagTimeMaxMs,</span><br><span class="hljs-comment">   * even if its log end offset is &gt;= HW. However, to be consistent with how the follower determines</span><br><span class="hljs-comment">   * whether a replica is in-sync, we only check HW.</span><br><span class="hljs-comment">   *</span><br><span class="hljs-comment">   * This function can be triggered when a replica&#x27;s LEO has incremented.</span><br><span class="hljs-comment">   */</span><br><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maybeExpandIsr</span></span>(followerReplica: <span class="hljs-type">Replica</span>): <span class="hljs-type">Unit</span> = &#123;<br>  <span class="hljs-keyword">val</span> needsIsrUpdate = !partitionState.isInflight &amp;&amp; canAddReplicaToIsr(followerReplica.brokerId) &amp;&amp; inReadLock(leaderIsrUpdateLock) &#123;<br>    needsExpandIsr(followerReplica)<br>  &#125;<br>  <span class="hljs-keyword">if</span> (needsIsrUpdate) &#123;<br>    <span class="hljs-keyword">val</span> alterIsrUpdateOpt = inWriteLock(leaderIsrUpdateLock) &#123;<br>      <span class="hljs-comment">// check if this replica needs to be added to the ISR  </span><br>      partitionState <span class="hljs-keyword">match</span> &#123;<br>        <span class="hljs-keyword">case</span> currentState: <span class="hljs-type">CommittedPartitionState</span> <span class="hljs-keyword">if</span> needsExpandIsr(followerReplica) =&gt;<br>          <span class="hljs-type">Some</span>(prepareIsrExpand(currentState, followerReplica.brokerId))<br>        <span class="hljs-keyword">case</span> _ =&gt;<br>          <span class="hljs-type">None</span><br>      &#125;<br>    &#125;<br>    <span class="hljs-comment">// Send the AlterPartition request outside of the LeaderAndIsr lock since the completion logic  </span><br>    <span class="hljs-comment">// may increment the high watermark (and consequently complete delayed operations).  </span><br>    alterIsrUpdateOpt.foreach(submitAlterPartition)<br>  &#125;<br>&#125;<br><br><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">needsExpandIsr</span></span>(followerReplica: <span class="hljs-type">Replica</span>): <span class="hljs-type">Boolean</span> = &#123;<br>  canAddReplicaToIsr(followerReplica.brokerId) &amp;&amp; isFollowerInSync(followerReplica)<br>&#125;<br><br><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">canAddReplicaToIsr</span></span>(followerReplicaId: <span class="hljs-type">Int</span>): <span class="hljs-type">Boolean</span> = &#123;<br>  <span class="hljs-keyword">val</span> current = partitionState<br>  !current.isInflight &amp;&amp;<br>    !current.isr.contains(followerReplicaId) &amp;&amp;<br>    isReplicaIsrEligible(followerReplicaId)<br>&#125;<br><br><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">isFollowerInSync</span></span>(followerReplica: <span class="hljs-type">Replica</span>): <span class="hljs-type">Boolean</span> = &#123;<br>  leaderLogIfLocal.exists &#123; leaderLog =&gt;<br>    <span class="hljs-keyword">val</span> followerEndOffset = followerReplica.stateSnapshot.logEndOffset<br>    followerEndOffset &gt;= leaderLog.highWatermark &amp;&amp; leaderEpochStartOffsetOpt.exists(followerEndOffset &gt;= _)<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<ul>
<li>maybeIncrementLeaderHW会判断所有的replica的最小logEndOffset值，或者Isr集合有变化时，来判断是是否更新高水位</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs scala">  <span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Check and maybe increment the high watermark of the partition;</span><br><span class="hljs-comment">   * this function can be triggered when</span><br><span class="hljs-comment">   *</span><br><span class="hljs-comment">   * 1. Partition ISR changed</span><br><span class="hljs-comment">   * 2. Any replica&#x27;s LEO changed</span><br><span class="hljs-comment">   *</span><br><span class="hljs-comment">   * The HW is determined by the smallest log end offset among all replicas that are in sync; or are considered caught-up</span><br><span class="hljs-comment">   * and are allowed to join the ISR. This way, if a replica is considered caught-up, but its log end offset is smaller</span><br><span class="hljs-comment">   * than HW, we will wait for this replica to catch up to the HW before advancing the HW. This helps the situation when</span><br><span class="hljs-comment">   * the ISR only includes the leader replica and a follower tries to catch up. If we don&#x27;t wait for the follower when</span><br><span class="hljs-comment">   * advancing the HW, the follower&#x27;s log end offset may keep falling behind the HW (determined by the leader&#x27;s log end</span><br><span class="hljs-comment">   * offset) and therefore will never be added to ISR.</span><br><span class="hljs-comment">   *</span><br><span class="hljs-comment">   * With the addition of AlterPartition, we also consider newly added replicas as part of the ISR when advancing</span><br><span class="hljs-comment">   * the HW. These replicas have not yet been committed to the ISR by the controller, so we could revert to the previously</span><br><span class="hljs-comment">   * committed ISR. However, adding additional replicas to the ISR makes it more restrictive and therefore safe. We call</span><br><span class="hljs-comment">   * this set the &quot;maximal&quot; ISR. See KIP-497 for more details</span><br><span class="hljs-comment">   *</span><br><span class="hljs-comment">   * Note There is no need to acquire the leaderIsrUpdate lock here since all callers of this private API acquire that lock</span><br><span class="hljs-comment">   *</span><br><span class="hljs-comment">   * @return true if the HW was incremented, and false otherwise.</span><br><span class="hljs-comment">   */</span><br><br><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maybeIncrementLeaderHW</span></span>(leaderLog: <span class="hljs-type">UnifiedLog</span>, currentTimeMs: <span class="hljs-type">Long</span> = time.milliseconds): <span class="hljs-type">Boolean</span> = &#123;<br>  <span class="hljs-comment">// maybeIncrementLeaderHW is in the hot path, the following code is written to  </span><br>  <span class="hljs-comment">// avoid unnecessary collection generation  </span><br>  <span class="hljs-keyword">val</span> leaderLogEndOffset = leaderLog.logEndOffsetMetadata<br>  <span class="hljs-keyword">var</span> newHighWatermark = leaderLogEndOffset<br>  remoteReplicasMap.values.foreach &#123; replica =&gt;<br>    <span class="hljs-keyword">val</span> replicaState = replica.stateSnapshot<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">shouldWaitForReplicaToJoinIsr</span></span>: <span class="hljs-type">Boolean</span> = &#123;<br>      replicaState.isCaughtUp(leaderLogEndOffset.messageOffset, currentTimeMs, replicaLagTimeMaxMs) &amp;&amp;<br>        isReplicaIsrEligible(replica.brokerId)<br>    &#125;<br><br>    <span class="hljs-comment">// Note here we are using the &quot;maximal&quot;, see explanation above  </span><br>    <span class="hljs-keyword">if</span> (replicaState.logEndOffsetMetadata.messageOffset &lt; newHighWatermark.messageOffset &amp;&amp;<br>      (partitionState.maximalIsr.contains(replica.brokerId) || shouldWaitForReplicaToJoinIsr)<br>    ) &#123;<br>      newHighWatermark = replicaState.logEndOffsetMetadata<br>    &#125;<br>  &#125;<br><br>  leaderLog.maybeIncrementHighWatermark(newHighWatermark) <span class="hljs-keyword">match</span> &#123;<br>    <span class="hljs-keyword">case</span> <span class="hljs-type">Some</span>(oldHighWatermark) =&gt;<br>      debug(<span class="hljs-string">s&quot;High watermark updated from <span class="hljs-subst">$oldHighWatermark</span> to <span class="hljs-subst">$newHighWatermark</span>&quot;</span>)<br>      <span class="hljs-literal">true</span><br><br>    <span class="hljs-keyword">case</span> <span class="hljs-type">None</span> =&gt;<br>      <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">logEndOffsetString</span></span>: ((<span class="hljs-type">Int</span>, <span class="hljs-type">LogOffsetMetadata</span>)) =&gt; <span class="hljs-type">String</span> = &#123;<br>        <span class="hljs-keyword">case</span> (brokerId, logEndOffsetMetadata) =&gt; <span class="hljs-string">s&quot;replica <span class="hljs-subst">$brokerId</span>: <span class="hljs-subst">$logEndOffsetMetadata</span>&quot;</span><br>      &#125;<br><br>      <br>      <span class="hljs-literal">false</span><br>  &#125;<br>&#125;<br><br><br><span class="hljs-comment">// 调用maybeIncrementLeaderHW之前，会update caughtUpTime</span><br>      <span class="hljs-keyword">val</span> lastCaughtUpTime = <span class="hljs-keyword">if</span> (followerFetchOffsetMetadata.messageOffset &gt;= leaderEndOffset) &#123;<br>        math.max(currentReplicaState.lastCaughtUpTimeMs, followerFetchTimeMs)<br>      &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (followerFetchOffsetMetadata.messageOffset &gt;= currentReplicaState.lastFetchLeaderLogEndOffset) &#123;<br>        math.max(currentReplicaState.lastCaughtUpTimeMs, currentReplicaState.lastFetchTimeMs)<br>      &#125; <span class="hljs-keyword">else</span> &#123;<br>        currentReplicaState.lastCaughtUpTimeMs<br>      &#125;<br></code></pre></td></tr></table></figure>
<ul>
<li>如果leader的低水位(所有replica的最小startLogOffset)或者高水位有变化，就tryCompleteDelayedRequests</li>
</ul>
<ol start="2">
<li>当处理完remote replica的所有更新后，如果满足以下条件，就立即返回：</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">// Respond immediately if no remote fetches are required and any of the below conditions is true  </span><br><span class="hljs-comment">// 1) fetch request does not want to wait  </span><br><span class="hljs-comment">// 2) fetch request does not require any data  </span><br><span class="hljs-comment">// 3) has enough data to respond  </span><br><span class="hljs-comment">// 4) some error happens while reading data  </span><br><span class="hljs-comment">// 5) we found a diverging epoch  </span><br><span class="hljs-comment">// 6) has a preferred read replica</span><br></code></pre></td></tr></table></figure>
<ol start="3">
<li>否则就new DelayedFetch，将其放进延迟队列中，异步等待请求数据完成再发送</li>
<li>在调用结束后，会执行一次所有的DelayOperation</li>
</ol>
<h4 id="异常情况：">异常情况：</h4>
<p>  当Follower出现OFFSET_OUT_OF_RANGE异常时，则需要根据情况来进行重新fetch，下面是Kafka解释出现OUT_OF_RANGE的case：</p>
<ol>
<li>当ISR集合中的Replica都下线了，那么Follower变成了Leader，不久后old Leader又复活变成了Follower从新的Leader上进行同步，发现old Leader的logEndOffset&gt;newLeaderEndOffset,此时会将old leader的log进行截断，从新Leader的EndOffset后开始同步</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs scala"><br><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fetchOffsetAndTruncate</span></span>(topicPartition: <span class="hljs-type">TopicPartition</span>, topicId: <span class="hljs-type">Option</span>[<span class="hljs-type">Uuid</span>], currentLeaderEpoch: <span class="hljs-type">Int</span>): <span class="hljs-type">PartitionFetchState</span> = &#123;<br> <span class="hljs-keyword">val</span> replicaEndOffset = logEndOffset(topicPartition)<br><br> <span class="hljs-comment">/**</span><br><span class="hljs-comment">  * Unclean leader election: A follower goes down, in the meanwhile the leader keeps appending messages. The follower comes back up</span><br><span class="hljs-comment">  * and before it has completely caught up with the leader&#x27;s logs, all replicas in the ISR go down. The follower is now uncleanly</span><br><span class="hljs-comment">  * elected as the new leader, and it starts appending messages from the client. The old leader comes back up, becomes a follower</span><br><span class="hljs-comment">  * and it may discover that the current leader&#x27;s end offset is behind its own end offset.</span><br><span class="hljs-comment">  *</span><br><span class="hljs-comment">  * In such a case, truncate the current follower&#x27;s log to the current leader&#x27;s end offset and continue fetching.</span><br><span class="hljs-comment">  *</span><br><span class="hljs-comment">  * There is a potential for a mismatch between the logs of the two replicas here. We don&#x27;t fix this mismatch as of now.</span><br><span class="hljs-comment">  */</span><br> <span class="hljs-keyword">val</span> offsetAndEpoch = leader.fetchLatestOffset(topicPartition, currentLeaderEpoch)<br> <span class="hljs-keyword">val</span> leaderEndOffset = offsetAndEpoch.offset<br> <span class="hljs-keyword">if</span> (leaderEndOffset &lt; replicaEndOffset) &#123;<br>   warn(<span class="hljs-string">s&quot;Reset fetch offset for partition <span class="hljs-subst">$topicPartition</span> from <span class="hljs-subst">$replicaEndOffset</span> to current &quot;</span> +<br>     <span class="hljs-string">s&quot;leader&#x27;s latest offset <span class="hljs-subst">$leaderEndOffset</span>&quot;</span>)<br>   truncate(topicPartition, <span class="hljs-type">OffsetTruncationState</span>(leaderEndOffset, truncationCompleted = <span class="hljs-literal">true</span>))<br><br>   fetcherLagStats.getAndMaybePut(topicPartition).lag = <span class="hljs-number">0</span><br>   <span class="hljs-type">PartitionFetchState</span>(topicId, leaderEndOffset, <span class="hljs-type">Some</span>(<span class="hljs-number">0</span>), currentLeaderEpoch,<br>     state = <span class="hljs-type">Fetching</span>, lastFetchedEpoch = latestEpoch(topicPartition))<br> &#125; <span class="hljs-keyword">else</span> &#123;<br>   ...<br> &#125;<br></code></pre></td></tr></table></figure>
<ol start="2">
<li>Follower的logEndOffset&lt; Leader logStartOffset,则清空Follower的Offset，从Leader logStartOffset开始同步</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">val</span> offsetAndEpoch = leader.fetchEarliestOffset(topicPartition, currentLeaderEpoch)<br><span class="hljs-keyword">val</span> leaderStartOffset = offsetAndEpoch.offset<br><span class="hljs-keyword">val</span> offsetToFetch = <span class="hljs-type">Math</span>.max(leaderStartOffset, replicaEndOffset)<br><span class="hljs-comment">// Only truncate log when current leader&#x27;s log start offset is greater than follower&#x27;s log end offset.  </span><br><span class="hljs-keyword">if</span> (leaderStartOffset &gt; replicaEndOffset) &#123;<br>  warn(<span class="hljs-string">s&quot;Truncate fully and reset fetch offset for partition <span class="hljs-subst">$topicPartition</span> from <span class="hljs-subst">$replicaEndOffset</span> to the &quot;</span> +<br>    <span class="hljs-string">s&quot;current leader&#x27;s start offset <span class="hljs-subst">$leaderStartOffset</span> because the local replica&#x27;s end offset is smaller than the &quot;</span> +<br>    <span class="hljs-string">s&quot;current leader&#x27;s start offsets.&quot;</span>)<br>  truncateFullyAndStartAt(topicPartition, leaderStartOffset)<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>  info(<span class="hljs-string">s&quot;Reset fetch offset for partition <span class="hljs-subst">$topicPartition</span> from <span class="hljs-subst">$replicaEndOffset</span> to &quot;</span> +<br>    <span class="hljs-string">s&quot;the current local replica&#x27;s end offset <span class="hljs-subst">$offsetToFetch</span>&quot;</span>)<br>&#125;<br><br><span class="hljs-keyword">val</span> initialLag = leaderEndOffset - offsetToFetch<br>fetcherLagStats.getAndMaybePut(topicPartition).lag = initialLag<br><span class="hljs-type">PartitionFetchState</span>(topicId, offsetToFetch, <span class="hljs-type">Some</span>(initialLag), currentLeaderEpoch,<br>  state = <span class="hljs-type">Fetching</span>, lastFetchedEpoch = latestEpoch(topicPartition))<br></code></pre></td></tr></table></figure>
<p>下面总结一下fetch的流程：</p>
<img src="/2023/11/27/Kafka-fetch/IMG-20231127232715169.png" class="">
<ol>
<li>Follower副本发送FetchRequest，从对应分区中获取消息</li>
<li>当请求到对应Partition的Broker中，会从日志存储中读取数据，更新remote<br>
replica offset，检测是否需要更新ISR集合、HW等</li>
<li>之后ReplicaManager为FetchRequest生成DelayedFetch对象，交由<br>
delayedFetchPurgatory管理</li>
<li>准备FetchResponse返回给客户端</li>
<li>执行一次DelayOperation，比如看DelayProduce是否已经完成</li>
<li>客户端收到response后更新本地的partition的数据：HW、LEO</li>
</ol>

      
    </div>
    <footer class="article-footer">
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Consumer/" rel="tag">Consumer</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/" rel="tag">消息消费</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2024/01/03/classLoader/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          ClassLoader
        
      </div>
    </a>
  
  
    <a href="/2023/11/26/Kafka-replica-server/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">
        
          Kafka-replica-server
        
      </div>
    </a>
  
</nav>

  
</article>


</section>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 epic<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a><br>
      
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/archives" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="/js/clipboard.min.js"></script>
<script src="/js/jquery-1.4.3.min.js"></script>

<script src="/fancybox/jquery.fancybox-1.3.4.pack.js"></script>


<script src="/js/script.js"></script>






<script>
  MathJax = {
    options: {
      enableMenu: false
    },
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
    }
  };
</script>
<!-- <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    CommonHTML: {
      linebreaks: false
    }
  });
  </script> -->
<script type="text/javascript" id="MathJax-script" async
  src="/mathjax/tex-chtml.js">
</script>
<!-- <script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_CHTML">
</script> -->

  </div>
  
  <!-- 回到顶部按钮 -->
  <button id="back-to-top" title="回到顶部" aria-label="回到顶部">
    <i class="fa fa-chevron-up" aria-hidden="true"></i>
  </button>
</body>
</html>